# 数据一致性优化说明

## 一、数据一致性检查

### 1. SourceFile 删除检查

**位置**: `backend/app/api/v1/endpoints/source_files.py`

**检查内容**:
- 检查是否有 `ParsedResume` 引用此文件（通过 `file_hash`）
- 检查是否有 `CandidateResume` 引用此文件（通过 `source_file_path`）

**行为**:
- 如果有关联数据且未设置 `force=true`，则阻止删除并返回错误信息
- 如果设置了 `force=true`，允许删除（但关联数据中的引用可能失效）

**示例**:
```python
DELETE /api/v1/source-files/{file_id}?force=false
# 如果有关联数据，返回 400 错误：
# "无法删除：该文件关联了 2 个解析结果和 1 个推荐报告。如需强制删除，请设置 force=true"
```

### 2. ParsedResume 删除检查

**位置**: `backend/app/api/v1/endpoints/parsed_resumes.py`

**检查内容**:
- 检查是否有 `CandidateResume` 引用此解析结果（通过 `parsed_resume_id`）

**行为**:
- 如果有关联数据且未设置 `force=true`，则阻止删除并返回错误信息
- 如果设置了 `force=true`，允许删除（推荐报告中的 `parsed_resume_id` 会变成无效引用）

**示例**:
```python
DELETE /api/v1/parsed-resumes/{parsed_resume_id}?force=false
# 如果有关联数据，返回 400 错误：
# "无法删除：该解析结果关联了 3 个推荐报告。如需强制删除，请设置 force=true"
```

### 3. CandidateResume 删除

**位置**: `backend/app/api/v1/endpoints/resumes.py`

**说明**:
- 删除推荐报告不会影响关联的解析结果和源文件
- 这是合理的，因为一个解析结果可以生成多个推荐报告

## 二、数据库查询性能优化

### 1. 索引使用情况

**已优化的索引**:

1. **CandidateResume 表**:
   - `idx_candidate_resume_user_created`: `(user_id, created_at)` - 优化用户列表查询
   - `user_id`: 单列索引 - 优化用户过滤
   - `parsed_resume_id`: 单列索引 - 优化关联查询
   - `template_id`: 单列索引 - 优化模板关联查询
   - `created_at`: 单列索引 - 优化时间排序

2. **ParsedResume 表**:
   - `idx_parsed_user_created`: `(user_id, created_at)` - 优化用户列表查询
   - `user_id`: 单列索引 - 优化用户过滤
   - `file_hash`: 单列索引 - 优化去重查询
   - `created_at`: 单列索引 - 优化时间排序

3. **SourceFile 表**:
   - `idx_source_file_user_created`: `(user_id, created_at)` - 优化用户列表查询
   - `user_id`: 单列索引 - 优化用户过滤
   - `file_hash`: 单列索引 - 优化去重查询
   - `created_at`: 单列索引 - 优化时间排序

### 2. 查询优化

**优化点**:

1. **Eager Loading（预加载）**:
   - `resumes.py`: 使用 `joinedload` 预加载 `template` 和 `parsed_resume`，避免 N+1 查询问题
   - 原来：1 次主查询 + N 次关联查询（N = 记录数）
   - 现在：1 次主查询 + 1 次关联查询（JOIN）

2. **分页查询**:
   - 所有列表查询都使用 `offset` 和 `limit` 进行分页
   - 限制最大 `limit` 为 100，防止一次性加载过多数据

3. **索引利用**:
   - 所有列表查询都按 `created_at DESC` 排序，利用复合索引
   - 所有查询都先过滤 `user_id`，利用单列索引

### 3. 性能建议

**进一步优化建议**:

1. **搜索字段索引**:
   - 如果搜索功能使用频繁，可以考虑为 `candidate_name`、`title`、`file_name` 添加全文索引
   - PostgreSQL 支持 `GIN` 索引用于全文搜索

2. **分页总数优化**:
   - 当前 `get_resumes` 使用 `count()` 获取总数，在大数据量时可能较慢
   - 可以考虑使用近似计数（如 PostgreSQL 的 `pg_class.reltuples`）或缓存计数

3. **批量操作优化**:
   - 批量删除操作使用 `Promise.all`，但可以考虑使用数据库的批量删除（`bulk_delete`）

## 三、使用示例

### 删除操作示例

**安全删除（检查关联数据）**:
```bash
# 删除源文件（如果有关联数据，会阻止删除）
DELETE /api/v1/source-files/123

# 删除解析结果（如果有关联数据，会阻止删除）
DELETE /api/v1/parsed-resumes/456
```

**强制删除（忽略关联数据）**:
```bash
# 强制删除源文件（即使有关联数据）
DELETE /api/v1/source-files/123?force=true

# 强制删除解析结果（即使有关联数据）
DELETE /api/v1/parsed-resumes/456?force=true
```

## 四、注意事项

1. **数据完整性**:
   - 强制删除可能导致数据不一致（如 `parsed_resume_id` 指向不存在的记录）
   - 建议在生产环境中谨慎使用 `force=true`

2. **级联删除**:
   - 当前实现不包含级联删除功能
   - 如果需要级联删除，可以在删除前手动删除关联数据

3. **文件清理**:
   - 删除 `SourceFile` 记录时，文件本身不会被删除（注释掉的代码）
   - 这是为了避免误删被其他数据引用的文件
   - 文件清理功能在"低优先级任务"中实现

## 五、测试建议

1. **数据一致性测试**:
   - 测试删除有关联数据的记录（应该被阻止）
   - 测试强制删除（应该成功）
   - 测试删除后关联数据的引用状态

2. **性能测试**:
   - 测试大量数据下的列表查询性能
   - 测试搜索功能的性能
   - 测试批量删除的性能

3. **索引验证**:
   - 使用 `EXPLAIN ANALYZE` 验证查询是否使用了索引
   - 检查慢查询日志，识别未使用索引的查询

